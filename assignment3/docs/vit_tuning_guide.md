# Vision Transformer (ViT) è°ƒä¼˜å®Œå…¨æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [è¶…å‚æ•°è°ƒä¼˜](#è¶…å‚æ•°è°ƒä¼˜)
3. [æ¨¡å‹æ¶æ„é€‰æ‹©](#æ¨¡å‹æ¶æ„é€‰æ‹©)
4. [è®­ç»ƒæŠ€å·§](#è®­ç»ƒæŠ€å·§)
5. [æ­£åˆ™åŒ–ç­–ç•¥](#æ­£åˆ™åŒ–ç­–ç•¥)
6. [è¯Šæ–­å’Œè°ƒè¯•](#è¯Šæ–­å’Œè°ƒè¯•)
7. [å¸¸è§é—®é¢˜è§£å†³](#å¸¸è§é—®é¢˜è§£å†³)
8. [å®Œæ•´è®­ç»ƒé…ç½®ç¤ºä¾‹](#å®Œæ•´è®­ç»ƒé…ç½®ç¤ºä¾‹)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šè¿‡æ‹Ÿåˆæµ‹è¯•ï¼ˆå¿…åšï¼ï¼‰

åœ¨å¼€å§‹ä»»ä½•è°ƒä¼˜ä¹‹å‰ï¼Œ**å¿…é¡»**å…ˆç¡®ä¿æ¨¡å‹èƒ½åœ¨ä¸€ä¸ªå° batch ä¸Šè¿‡æ‹Ÿåˆåˆ° 100% å‡†ç¡®ç‡ã€‚

```python
import torch
import torch.nn as nn
from cs231n.classifiers.transformer import VisionTransformer

# 1. åˆ›å»ºå°æ•°æ®é›†
N = 32  # å°batch
X = torch.randn(N, 3, 32, 32)
y = torch.randint(0, 10, (N,))

# 2. åˆ›å»ºæ¨¡å‹ï¼ˆå…³é—­ dropoutï¼‰
model = VisionTransformer(
    img_size=32,
    patch_size=8,
    in_channels=3,
    embed_dim=128,
    num_layers=6,
    num_heads=4,
    dim_feedforward=256,
    num_classes=10,
    dropout=0.0  # â† å…³é”®ï¼šè¿‡æ‹Ÿåˆæ—¶ä¸è¦ dropout
)

# 3. è®­ç»ƒé…ç½®
optimizer = torch.optim.Adam(
    model.parameters(),
    lr=5e-3,           # â† è¾ƒå¤§å­¦ä¹ ç‡
    weight_decay=0.0   # â† æ— æ­£åˆ™åŒ–
)
criterion = nn.CrossEntropyLoss()

# 4. è®­ç»ƒå¾ªç¯
for step in range(200):
    optimizer.zero_grad()
    output = model(X)
    loss = criterion(output, y)
    loss.backward()
    optimizer.step()

    if step % 50 == 0:
        acc = (output.argmax(1) == y).float().mean()
        print(f"[{step}/200] Loss: {loss.item():.4f}, Acc: {acc.item():.4f}")

# æœŸæœ›ç»“æœï¼šAccuracy åº”è¯¥è¾¾åˆ° 1.0 (100%)
```

**âœ“ å¦‚æœèƒ½è¿‡æ‹Ÿåˆ** â†’ å®ç°æ­£ç¡®ï¼Œç»§ç»­è°ƒä¼˜
**âœ— å¦‚æœä¸èƒ½è¿‡æ‹Ÿåˆ** â†’ å®ç°æœ‰ bugï¼Œå…ˆä¿®å¤å†ç»§ç»­

---

## âš™ï¸ è¶…å‚æ•°è°ƒä¼˜

### 1. å­¦ä¹ ç‡ï¼ˆæœ€é‡è¦ï¼ï¼‰

å­¦ä¹ ç‡æ˜¯**æœ€é‡è¦**çš„è¶…å‚æ•°ï¼Œå¯¹è®­ç»ƒå½±å“æœ€å¤§ã€‚

#### æ¨èèŒƒå›´

| æ•°æ®é›†å¤§å° | åˆå§‹å­¦ä¹ ç‡ | è¯´æ˜ |
|-----------|-----------|------|
| å°æ•°æ®é›† (<10K) | 1e-4 ~ 5e-4 | è¾ƒå°ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ |
| ä¸­ç­‰æ•°æ®é›† (10K~100K) | 3e-4 ~ 1e-3 | ä¸­ç­‰ |
| å¤§æ•°æ®é›† (>100K) | 1e-3 ~ 5e-3 | è¾ƒå¤§ï¼ŒåŠ é€Ÿè®­ç»ƒ |
| **è¿‡æ‹Ÿåˆæµ‹è¯•** | 5e-3 ~ 1e-2 | æœ€å¤§ï¼Œå¿«é€ŸéªŒè¯ |

#### å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰

```python
# æ–¹æ¡ˆ 1: Cosine Annealingï¼ˆæ¨èï¼‰
from torch.optim.lr_scheduler import CosineAnnealingLR

scheduler = CosineAnnealingLR(
    optimizer,
    T_max=num_epochs,  # å‘¨æœŸé•¿åº¦
    eta_min=1e-6       # æœ€å°å­¦ä¹ ç‡
)

# ä½¿ç”¨
for epoch in range(num_epochs):
    train_one_epoch(...)
    scheduler.step()  # æ¯ä¸ª epoch åæ›´æ–°

# æ–¹æ¡ˆ 2: Step Decay
from torch.optim.lr_scheduler import StepLR

scheduler = StepLR(
    optimizer,
    step_size=30,   # æ¯ 30 epochs
    gamma=0.1       # å­¦ä¹ ç‡è¡°å‡ä¸ºåŸæ¥çš„ 0.1
)

# æ–¹æ¡ˆ 3: Reduce on Plateauï¼ˆæ ¹æ®éªŒè¯é›†ï¼‰
from torch.optim.lr_scheduler import ReduceLROnPlateau

scheduler = ReduceLROnPlateau(
    optimizer,
    mode='max',          # ç›‘æ§å‡†ç¡®ç‡ï¼ˆmaxï¼‰æˆ–lossï¼ˆminï¼‰
    factor=0.5,          # è¡°å‡å› å­
    patience=5,          # å®¹å¿ 5 ä¸ª epoch ä¸æå‡
    verbose=True
)

# ä½¿ç”¨
for epoch in range(num_epochs):
    train_loss = train_one_epoch(...)
    val_acc = validate(...)
    scheduler.step(val_acc)  # ä¼ å…¥ç›‘æ§æŒ‡æ ‡
```

#### å­¦ä¹ ç‡ Warmupï¼ˆå¤§æ¨¡å‹å¿…éœ€ï¼‰

```python
class WarmupScheduler:
    """å­¦ä¹ ç‡é¢„çƒ­ + Cosine Annealing"""
    def __init__(self, optimizer, warmup_epochs, total_epochs,
                 base_lr, warmup_lr=0):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.base_lr = base_lr
        self.warmup_lr = warmup_lr
        self.current_epoch = 0

    def step(self):
        if self.current_epoch < self.warmup_epochs:
            # Warmup é˜¶æ®µï¼šçº¿æ€§å¢é•¿
            lr = self.warmup_lr + (self.base_lr - self.warmup_lr) * \
                 (self.current_epoch / self.warmup_epochs)
        else:
            # Cosine Annealing é˜¶æ®µ
            progress = (self.current_epoch - self.warmup_epochs) / \
                      (self.total_epochs - self.warmup_epochs)
            lr = self.base_lr * 0.5 * (1 + math.cos(math.pi * progress))

        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr

        self.current_epoch += 1
        return lr

# ä½¿ç”¨
scheduler = WarmupScheduler(
    optimizer,
    warmup_epochs=5,      # å‰ 5 ä¸ª epoch é¢„çƒ­
    total_epochs=100,
    base_lr=1e-3,
    warmup_lr=1e-6
)

for epoch in range(100):
    lr = scheduler.step()
    print(f"Epoch {epoch}: LR = {lr:.6f}")
    train_one_epoch(...)
```

### 2. Batch Size

#### æ¨èå€¼

| GPU å†…å­˜ | Batch Size | è¯´æ˜ |
|---------|-----------|------|
| 4GB | 32-64 | å°æ¨¡å‹ |
| 8GB | 64-128 | ä¸­ç­‰ |
| 16GB+ | 128-256 | å¤§æ¨¡å‹ |

#### Batch Size ä¸å­¦ä¹ ç‡çš„å…³ç³»

**é‡è¦è§„åˆ™**ï¼šBatch size å¢å¤§æ—¶ï¼Œå­¦ä¹ ç‡ä¹Ÿåº”è¯¥ç›¸åº”å¢å¤§ã€‚

```python
# çº¿æ€§ç¼©æ”¾è§„åˆ™ï¼ˆLinear Scaling Ruleï¼‰
base_batch_size = 64
base_lr = 1e-3

your_batch_size = 256
your_lr = base_lr * (your_batch_size / base_batch_size)
# your_lr = 1e-3 * (256 / 64) = 4e-3
```

#### å°æŠ€å·§ï¼šæ¢¯åº¦ç´¯ç§¯ï¼ˆGradient Accumulationï¼‰

å¦‚æœ GPU å†…å­˜ä¸å¤Ÿï¼Œå¯ä»¥ç”¨æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§ batch sizeï¼š

```python
accumulation_steps = 4  # ç´¯ç§¯ 4 ä¸ª batch
optimizer.zero_grad()

for i, (x, y) in enumerate(dataloader):
    output = model(x)
    loss = criterion(output, y) / accumulation_steps  # ç¼©æ”¾ loss
    loss.backward()

    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()

# ç­‰æ•ˆäº batch_size * accumulation_steps çš„å¤§ batch
```

### 3. Weight Decayï¼ˆæƒé‡è¡°å‡ï¼‰

Weight decay æ˜¯ L2 æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

#### æ¨èèŒƒå›´

| æ•°æ®é›†å¤§å° | Weight Decay | è¯´æ˜ |
|-----------|-------------|------|
| è¿‡æ‹Ÿåˆæµ‹è¯• | 0.0 | ä¸è¦æ­£åˆ™åŒ– |
| å°æ•°æ®é›† | 1e-3 ~ 5e-3 | å¼ºæ­£åˆ™åŒ– |
| ä¸­ç­‰æ•°æ®é›† | 1e-4 ~ 1e-3 | ä¸­ç­‰ |
| å¤§æ•°æ®é›† | 1e-5 ~ 1e-4 | è½»å¾® |

#### é«˜çº§æŠ€å·§ï¼šä¸å¯¹æ‰€æœ‰å‚æ•°åº”ç”¨ weight decay

```python
# ä¸å¯¹ bias å’Œ LayerNorm å‚æ•°åº”ç”¨ weight decay
def get_parameter_groups(model, weight_decay):
    decay = []
    no_decay = []

    for name, param in model.named_parameters():
        if not param.requires_grad:
            continue
        # Bias å’Œ LayerNorm å‚æ•°ä¸åº”ç”¨ weight decay
        if 'bias' in name or 'norm' in name:
            no_decay.append(param)
        else:
            decay.append(param)

    return [
        {'params': decay, 'weight_decay': weight_decay},
        {'params': no_decay, 'weight_decay': 0.0}
    ]

# ä½¿ç”¨
param_groups = get_parameter_groups(model, weight_decay=1e-4)
optimizer = torch.optim.AdamW(param_groups, lr=1e-3)
```

### 4. Dropout

Dropout åœ¨æ¯ä¸ªå­å±‚ä¹‹ååº”ç”¨ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

#### æ¨èå€¼

| åœºæ™¯ | Dropout Rate | è¯´æ˜ |
|------|-------------|------|
| è¿‡æ‹Ÿåˆæµ‹è¯• | 0.0 | ä¸è¦ dropout |
| å°æ•°æ®é›† | 0.3 ~ 0.5 | å¼º dropout |
| ä¸­ç­‰æ•°æ®é›† | 0.1 ~ 0.3 | ä¸­ç­‰ |
| å¤§æ•°æ®é›† | 0.0 ~ 0.1 | è½»å¾®æˆ–æ—  |

```python
model = VisionTransformer(
    ...,
    dropout=0.1  # 10% dropout
)
```

### 5. Optimizer é€‰æ‹©

#### Adam vs AdamW vs SGD

| Optimizer | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåœºæ™¯ |
|-----------|------|------|---------|
| **Adam** | æ”¶æ•›å¿«ï¼Œè‡ªé€‚åº”å­¦ä¹ ç‡ | æ³›åŒ–ç•¥å·® | å¿«é€Ÿå®éªŒ |
| **AdamW** | æ”¶æ•›å¿«ï¼Œæ›´å¥½çš„æ­£åˆ™åŒ– | - | **æ¨è** |
| **SGD+Momentum** | æ³›åŒ–æœ€å¥½ | éœ€è¦ä»”ç»†è°ƒå‚ | æœ€ç»ˆæ¨¡å‹ |

```python
# æ¨èï¼šAdamW
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=1e-3,
    betas=(0.9, 0.999),    # é»˜è®¤å€¼
    weight_decay=1e-4
)

# æ›¿ä»£ï¼šSGD with Momentum
optimizer = torch.optim.SGD(
    model.parameters(),
    lr=1e-2,               # SGD éœ€è¦æ›´å¤§çš„å­¦ä¹ ç‡
    momentum=0.9,
    weight_decay=1e-4,
    nesterov=True          # Nesterov åŠ é€Ÿ
)
```

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„é€‰æ‹©

### 1. Embed Dimensionï¼ˆåµŒå…¥ç»´åº¦ï¼‰

æ§åˆ¶æ¨¡å‹çš„"å®½åº¦"ã€‚

| æ¨¡å‹å¤§å° | Embed Dim | Parameters | ç”¨é€” |
|---------|-----------|-----------|------|
| Tiny | 64-128 | ~100K | å¿«é€Ÿå®éªŒã€å°æ•°æ®é›† |
| Small | 256-384 | ~1M | ä¸­ç­‰æ•°æ®é›† |
| Base | 512-768 | ~10M | æ ‡å‡†é…ç½® |
| Large | 1024 | ~100M | å¤§æ•°æ®é›†ã€SOTA |

### 2. Number of Headsï¼ˆæ³¨æ„åŠ›å¤´æ•°ï¼‰

å¿…é¡»æ»¡è¶³ï¼š`embed_dim % num_heads == 0`

| Embed Dim | æ¨è Heads | Head Dim |
|-----------|-----------|----------|
| 128 | 4 or 8 | 32 or 16 |
| 256 | 4 or 8 | 64 or 32 |
| 512 | 8 | 64 |
| 768 | 12 | 64 |
| 1024 | 16 | 64 |

**ç»éªŒæ³•åˆ™**ï¼šHead dimension ä¿æŒåœ¨ 32-64 ä¹‹é—´æ•ˆæœæœ€å¥½ã€‚

### 3. Number of Layersï¼ˆå±‚æ•°ï¼‰

æ§åˆ¶æ¨¡å‹çš„"æ·±åº¦"ã€‚

| å±‚æ•° | ç”¨é€” | è¯´æ˜ |
|------|------|------|
| 2-4 | å¿«é€Ÿå®éªŒ | è®­ç»ƒå¿«ï¼Œé€‚åˆè°ƒå‚ |
| 6-8 | æ ‡å‡†é…ç½® | æ€§èƒ½ä¸é€Ÿåº¦å¹³è¡¡ |
| 12 | Base æ¨¡å‹ | éœ€è¦æ›´å¤šæ•°æ® |
| 24+ | Large æ¨¡å‹ | éœ€è¦å¤§æ•°æ®é›†å’Œé•¿æ—¶é—´è®­ç»ƒ |

### 4. Feedforward Dimension

é€šå¸¸æ˜¯ `embed_dim` çš„ 2-4 å€ã€‚

```python
dim_feedforward = embed_dim * 4  # æ ‡å‡†é…ç½®
```

| Embed Dim | Feedforward Dim |
|-----------|----------------|
| 128 | 512 |
| 256 | 1024 |
| 512 | 2048 |
| 768 | 3072 |

### 5. Patch Sizeï¼ˆViT ç‰¹æœ‰ï¼‰

Patch size å½±å“åºåˆ—é•¿åº¦å’Œè®¡ç®—é‡ã€‚

#### å¯¹äº 32Ã—32 å›¾åƒï¼ˆCIFAR-10ï¼‰

| Patch Size | Num Patches | è®¡ç®—é‡ | æ€§èƒ½ |
|-----------|-------------|-------|------|
| 4Ã—4 | 64 | é«˜ | æœ€å¥½ï¼ˆç»†ç²’åº¦ï¼‰|
| 8Ã—8 | 16 | ä¸­ | è‰¯å¥½ï¼ˆæ¨èï¼‰|
| 16Ã—16 | 4 | ä½ | è¾ƒå·®ï¼ˆå¤ªç²—ç³™ï¼‰|

#### å¯¹äº 224Ã—224 å›¾åƒï¼ˆImageNetï¼‰

| Patch Size | Num Patches | è®¡ç®—é‡ | å¸¸ç”¨æ¨¡å‹ |
|-----------|-------------|-------|---------|
| 16Ã—16 | 196 | é«˜ | ViT-Base/16 |
| 32Ã—32 | 49 | ä½ | ViT-Base/32 |

**ç»éªŒæ³•åˆ™**ï¼š
- å›¾åƒè¶Šå¤§ï¼Œpatch size å¯ä»¥è¶Šå¤§
- Patch size è¶Šå°ï¼Œæ€§èƒ½è¶Šå¥½ï¼Œä½†è®¡ç®—é‡è¶Šå¤§

### 6. æ¨¡å‹é…ç½®ç¤ºä¾‹

```python
# Tiny (å¿«é€Ÿå®éªŒ)
model = VisionTransformer(
    img_size=32,
    patch_size=8,
    embed_dim=128,
    num_layers=4,
    num_heads=4,
    dim_feedforward=512,
    dropout=0.1
)
# Parameters: ~200K

# Small (ä¸­ç­‰æ€§èƒ½)
model = VisionTransformer(
    img_size=32,
    patch_size=8,
    embed_dim=256,
    num_layers=6,
    num_heads=8,
    dim_feedforward=1024,
    dropout=0.1
)
# Parameters: ~2M

# Base (æ ‡å‡†é…ç½®)
model = VisionTransformer(
    img_size=32,
    patch_size=8,
    embed_dim=512,
    num_layers=6,
    num_heads=8,
    dim_feedforward=2048,
    dropout=0.1
)
# Parameters: ~10M
```

---

## ğŸ“ è®­ç»ƒæŠ€å·§

### 1. æ•°æ®å¢å¼ºï¼ˆData Augmentationï¼‰

ViT æ¯” CNN æ›´ä¾èµ–æ•°æ®å¢å¼ºï¼

```python
import torchvision.transforms as transforms

# åŸºç¡€å¢å¼ºï¼ˆæ¨èï¼‰
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),      # éšæœºè£å‰ª
    transforms.RandomHorizontalFlip(p=0.5),    # éšæœºæ°´å¹³ç¿»è½¬
    transforms.ColorJitter(                    # é¢œè‰²æŠ–åŠ¨
        brightness=0.2,
        contrast=0.2,
        saturation=0.2,
        hue=0.1
    ),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], # æ ‡å‡†åŒ–
                        std=[0.5, 0.5, 0.5])
])

# å¼ºå¢å¼ºï¼ˆå¤§æ•°æ®é›†ï¼‰
from torchvision.transforms import RandAugment

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(32),
    transforms.RandomHorizontalFlip(),
    RandAugment(num_ops=2, magnitude=9),      # RandAugment
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5])
])

# éªŒè¯é›†ï¼ˆåªæ ‡å‡†åŒ–ï¼‰
val_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5])
])
```

### 2. Mixup / Cutmix

é«˜çº§æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œåœ¨è®­ç»ƒæ—¶æ··åˆæ ·æœ¬ã€‚

```python
def mixup_data(x, y, alpha=1.0):
    """Mixup augmentation"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size(0)
    index = torch.randperm(batch_size)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

# ä½¿ç”¨
for x, y in dataloader:
    x, y_a, y_b, lam = mixup_data(x, y, alpha=0.2)
    output = model(x)
    loss = lam * criterion(output, y_a) + (1 - lam) * criterion(output, y_b)
    loss.backward()
    optimizer.step()
```

### 3. Label Smoothing

å‡å°‘è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–ã€‚

```python
# PyTorch å†…ç½®æ”¯æŒ
criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

# æ‰‹åŠ¨å®ç°
class LabelSmoothingCrossEntropy(nn.Module):
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, pred, target):
        confidence = 1.0 - self.smoothing
        n_classes = pred.size(-1)

        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (n_classes - 1))
            true_dist.scatter_(1, target.unsqueeze(1), confidence)

        return torch.mean(torch.sum(-true_dist * F.log_softmax(pred, dim=-1), dim=-1))

criterion = LabelSmoothingCrossEntropy(smoothing=0.1)
```

### 4. æ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰

é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ã€‚

```python
# æ–¹æ³• 1: Clip by normï¼ˆæ¨èï¼‰
max_grad_norm = 1.0
torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)

# æ–¹æ³• 2: Clip by value
max_grad_value = 0.5
torch.nn.utils.clip_grad_value_(model.parameters(), max_grad_value)

# å®Œæ•´è®­ç»ƒå¾ªç¯
for x, y in dataloader:
    optimizer.zero_grad()
    output = model(x)
    loss = criterion(output, y)
    loss.backward()

    # æ¢¯åº¦è£å‰ª
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

    optimizer.step()
```

### 5. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆMixed Precisionï¼‰

åŠ é€Ÿè®­ç»ƒï¼Œå‡å°‘å†…å­˜ä½¿ç”¨ã€‚

```python
from torch.cuda.amp import autocast, GradScaler

# åˆ›å»º GradScaler
scaler = GradScaler()

for x, y in dataloader:
    optimizer.zero_grad()

    # åœ¨ autocast ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œå‰å‘ä¼ æ’­
    with autocast():
        output = model(x)
        loss = criterion(output, y)

    # ç¼©æ”¾ lossï¼Œåå‘ä¼ æ’­
    scaler.scale(loss).backward()

    # æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼‰
    scaler.unscale_(optimizer)
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

    # æ›´æ–°æƒé‡
    scaler.step(optimizer)
    scaler.update()

# åŠ é€Ÿï¼š1.5-2xï¼Œå†…å­˜å‡å°‘ï¼š~50%
```

### 6. Early Stopping

é˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒèŠ‚çœæ—¶é—´ã€‚

```python
class EarlyStopping:
    def __init__(self, patience=7, delta=0):
        self.patience = patience
        self.delta = delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_acc_max = -np.inf

    def __call__(self, val_acc, model):
        score = val_acc

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_acc, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter}/{self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_acc, model)
            self.counter = 0

    def save_checkpoint(self, val_acc, model):
        print(f'Validation accuracy increased ({self.val_acc_max:.4f} â†’ {val_acc:.4f}). Saving model...')
        torch.save(model.state_dict(), 'best_model.pt')
        self.val_acc_max = val_acc

# ä½¿ç”¨
early_stopping = EarlyStopping(patience=10)

for epoch in range(num_epochs):
    train_loss = train_one_epoch(...)
    val_acc = validate(...)

    early_stopping(val_acc, model)
    if early_stopping.early_stop:
        print("Early stopping triggered!")
        break
```

---

## ğŸ›¡ï¸ æ­£åˆ™åŒ–ç­–ç•¥

### 1. Stochastic Depthï¼ˆéšæœºæ·±åº¦ï¼‰

è®­ç»ƒæ—¶éšæœºè·³è¿‡æŸäº›å±‚ï¼Œæµ‹è¯•æ—¶ä½¿ç”¨æ‰€æœ‰å±‚ã€‚

```python
class StochasticDepth(nn.Module):
    """éšæœºæ·±åº¦æ­£åˆ™åŒ–"""
    def __init__(self, drop_prob=0.1):
        super().__init__()
        self.drop_prob = drop_prob

    def forward(self, x, residual):
        if not self.training or self.drop_prob == 0:
            return x + residual

        # ä»¥ä¸€å®šæ¦‚ç‡è·³è¿‡å½“å‰å±‚
        keep_prob = 1 - self.drop_prob
        random_tensor = keep_prob + torch.rand(
            (x.size(0), 1, 1), dtype=x.dtype, device=x.device
        )
        binary_tensor = torch.floor(random_tensor)

        # è®­ç»ƒæ—¶ç¼©æ”¾
        return x + residual * binary_tensor / keep_prob

# åœ¨ TransformerEncoderLayer ä¸­ä½¿ç”¨
class TransformerEncoderLayerWithSD(nn.Module):
    def __init__(self, ..., drop_path=0.1):
        super().__init__()
        self.stochastic_depth = StochasticDepth(drop_path)
        ...

    def forward(self, src):
        # Self-attention
        shortcut = src
        src = self.self_attn(...)
        src = self.dropout(src)
        src = self.stochastic_depth(shortcut, src)  # ä½¿ç”¨éšæœºæ·±åº¦
        src = self.norm(src)
        ...
```

### 2. æ­£åˆ™åŒ–ç»„åˆç­–ç•¥

| æ•°æ®é›†å¤§å° | Dropout | Weight Decay | Stochastic Depth | æ•°æ®å¢å¼º |
|-----------|---------|--------------|------------------|---------|
| å° (<10K) | 0.3-0.5 | 1e-3 ~ 5e-3 | 0.2-0.3 | å¼º |
| ä¸­ (10K~100K) | 0.1-0.3 | 1e-4 ~ 1e-3 | 0.1-0.2 | ä¸­ç­‰ |
| å¤§ (>100K) | 0.0-0.1 | 1e-5 ~ 1e-4 | 0.0-0.1 | åŸºç¡€ |

---

## ğŸ” è¯Šæ–­å’Œè°ƒè¯•

### 1. å­¦ä¹ æ›²çº¿åˆ†æ

```python
import matplotlib.pyplot as plt

def plot_learning_curves(train_losses, val_losses, train_accs, val_accs):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # Loss æ›²çº¿
    ax1.plot(train_losses, label='Train Loss')
    ax1.plot(val_losses, label='Val Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.set_title('Loss Curves')

    # Accuracy æ›²çº¿
    ax2.plot(train_accs, label='Train Acc')
    ax2.plot(val_accs, label='Val Acc')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()
    ax2.set_title('Accuracy Curves')

    plt.tight_layout()
    plt.savefig('learning_curves.png')
    plt.show()

# è¯Šæ–­æŒ‡å—
"""
æƒ…å†µ 1: Train loss ä¸‹é™ï¼ŒVal loss ä¸Šå‡
  â†’ è¿‡æ‹Ÿåˆï¼
  â†’ è§£å†³ï¼šå¢åŠ  dropout, weight decay, æ•°æ®å¢å¼º

æƒ…å†µ 2: Train loss å’Œ Val loss éƒ½å¾ˆé«˜
  â†’ æ¬ æ‹Ÿåˆï¼
  â†’ è§£å†³ï¼šå¢å¤§æ¨¡å‹å®¹é‡ï¼Œé™ä½æ­£åˆ™åŒ–ï¼Œå¢åŠ è®­ç»ƒæ—¶é—´

æƒ…å†µ 3: Train loss å¾ˆä½ï¼ŒVal loss ç¨é«˜ä½†ç¨³å®š
  â†’ æ­£å¸¸ï¼è½»å¾®è¿‡æ‹Ÿåˆæ˜¯å¯ä»¥æ¥å—çš„

æƒ…å†µ 4: Loss éœ‡è¡ï¼Œä¸ç¨³å®š
  â†’ å­¦ä¹ ç‡å¤ªå¤§ï¼
  â†’ è§£å†³ï¼šé™ä½å­¦ä¹ ç‡ï¼Œä½¿ç”¨æ¢¯åº¦è£å‰ª
"""
```

### 2. æ¢¯åº¦ç›‘æ§

```python
def monitor_gradients(model):
    """ç›‘æ§æ¢¯åº¦ç»Ÿè®¡"""
    total_norm = 0
    for name, param in model.named_parameters():
        if param.grad is not None:
            param_norm = param.grad.data.norm(2)
            total_norm += param_norm.item() ** 2

            # æ‰“å°æ¯å±‚çš„æ¢¯åº¦
            if param_norm > 10:  # è­¦å‘Šï¼šæ¢¯åº¦è¿‡å¤§
                print(f"âš ï¸  Large gradient in {name}: {param_norm:.4f}")

    total_norm = total_norm ** 0.5
    print(f"Total gradient norm: {total_norm:.4f}")

    # åˆ¤æ–­
    if total_norm > 100:
        print("âŒ Gradient explosion! Consider gradient clipping.")
    elif total_norm < 1e-6:
        print("âŒ Gradient vanishing! Check your model.")

# ä½¿ç”¨
for epoch in range(num_epochs):
    for x, y in dataloader:
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        loss.backward()

        monitor_gradients(model)  # ç›‘æ§

        optimizer.step()
```

### 3. Attention Visualization

```python
def visualize_attention(model, image, layer_idx=0, head_idx=0):
    """å¯è§†åŒ–æ³¨æ„åŠ›å›¾"""
    model.eval()
    with torch.no_grad():
        # å‰å‘ä¼ æ’­ï¼Œä¿å­˜æ³¨æ„åŠ›æƒé‡
        # éœ€è¦ä¿®æ”¹ MultiHeadAttention çš„ forward è¿”å› attention weights
        patches = model.patch_embed(image.unsqueeze(0))
        patches = model.positional_encoding(patches)

        # è·å–ç‰¹å®šå±‚çš„æ³¨æ„åŠ›æƒé‡
        attn_weights = []
        for i, layer in enumerate(model.transformer.layers):
            # éœ€è¦åœ¨ self_attn ä¸­è¿”å› attention weights
            patches, attn = layer(patches, return_attention=True)
            attn_weights.append(attn)

        # é€‰æ‹©ç‰¹å®šå±‚å’Œå¤´
        attn = attn_weights[layer_idx][0, head_idx]  # (num_patches, num_patches)

        # å¯è§†åŒ–
        plt.figure(figsize=(10, 10))
        plt.imshow(attn.cpu().numpy(), cmap='viridis')
        plt.colorbar()
        plt.title(f'Attention Map - Layer {layer_idx}, Head {head_idx}')
        plt.show()
```

### 4. å¿«é€Ÿè¯Šæ–­æ£€æŸ¥æ¸…å•

```python
def diagnostic_check(model, dataloader, device='cuda'):
    """å…¨é¢è¯Šæ–­æ£€æŸ¥"""
    model.to(device)
    model.train()

    print("=" * 60)
    print("DIAGNOSTIC CHECK")
    print("=" * 60)

    # 1. æ£€æŸ¥å‰å‘ä¼ æ’­
    print("\n1. Forward Pass Check")
    try:
        x, y = next(iter(dataloader))
        x, y = x.to(device), y.to(device)
        output = model(x)
        print(f"   âœ“ Input shape: {x.shape}")
        print(f"   âœ“ Output shape: {output.shape}")
        print(f"   âœ“ Output range: [{output.min():.4f}, {output.max():.4f}]")
    except Exception as e:
        print(f"   âœ— Error: {e}")
        return

    # 2. æ£€æŸ¥åå‘ä¼ æ’­
    print("\n2. Backward Pass Check")
    try:
        criterion = nn.CrossEntropyLoss()
        loss = criterion(output, y)
        loss.backward()
        print(f"   âœ“ Loss: {loss.item():.4f}")

        has_grad = any(p.grad is not None and p.grad.abs().sum() > 0
                      for p in model.parameters())
        print(f"   âœ“ Gradients present: {has_grad}")
    except Exception as e:
        print(f"   âœ— Error: {e}")
        return

    # 3. æ£€æŸ¥å‚æ•°æ•°é‡
    print("\n3. Model Size Check")
    num_params = sum(p.numel() for p in model.parameters())
    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"   Total parameters: {num_params:,}")
    print(f"   Trainable parameters: {num_trainable:,}")
    print(f"   Model size: {num_params * 4 / 1024 / 1024:.2f} MB (fp32)")

    # 4. æ£€æŸ¥è¿‡æ‹Ÿåˆèƒ½åŠ›
    print("\n4. Overfitting Test (100 steps)")
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)

    for step in range(100):
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()

        if step % 25 == 0 or step == 99:
            acc = (output.argmax(1) == y).float().mean()
            print(f"   [{step:3d}/100] Loss: {loss.item():.4f}, Acc: {acc:.4f}")

    final_acc = (output.argmax(1) == y).float().mean().item()
    if final_acc > 0.95:
        print(f"   âœ“ Can overfit! Final accuracy: {final_acc:.4f}")
    else:
        print(f"   âœ— Cannot overfit. Final accuracy: {final_acc:.4f}")
        print(f"   â†’ Check implementation or increase learning rate")

    print("\n" + "=" * 60)
    print("DIAGNOSTIC COMPLETE")
    print("=" * 60)

# ä½¿ç”¨
diagnostic_check(model, train_loader)
```

---

## â“ å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜ 1: è®­ç»ƒ loss ä¸ä¸‹é™

**å¯èƒ½åŸå› **ï¼š
- å­¦ä¹ ç‡å¤ªå°
- å­¦ä¹ ç‡å¤ªå¤§ï¼ˆå¯¼è‡´éœ‡è¡ï¼‰
- å®ç°æœ‰ bug

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# 1. å…ˆåšè¿‡æ‹Ÿåˆæµ‹è¯•
# å¦‚æœèƒ½è¿‡æ‹Ÿåˆ â†’ å­¦ä¹ ç‡é—®é¢˜
# å¦‚æœä¸èƒ½è¿‡æ‹Ÿåˆ â†’ å®ç°bug

# 2. å°è¯•ä¸åŒå­¦ä¹ ç‡
for lr in [1e-2, 5e-3, 1e-3, 5e-4, 1e-4]:
    print(f"\nTrying lr={lr}")
    test_learning_rate(model, dataloader, lr, num_steps=50)

# 3. æ£€æŸ¥æ¢¯åº¦
monitor_gradients(model)
```

### é—®é¢˜ 2: éªŒè¯é›†å‡†ç¡®ç‡ä½äºè®­ç»ƒé›†å¾ˆå¤š

**å¯èƒ½åŸå› **ï¼šè¿‡æ‹Ÿåˆ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¢åŠ æ­£åˆ™åŒ–
model = VisionTransformer(..., dropout=0.2)  # å¢å¤§ dropout

optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=1e-3,
    weight_decay=1e-3  # å¢å¤§ weight decay
)

# å¢åŠ æ•°æ®å¢å¼º
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))
])
```

### é—®é¢˜ 3: Loss å˜æˆ NaN

**å¯èƒ½åŸå› **ï¼š
- å­¦ä¹ ç‡å¤ªå¤§
- æ¢¯åº¦çˆ†ç‚¸
- æ•°å€¼ä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# 1. é™ä½å­¦ä¹ ç‡
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # æ›´å°

# 2. æ·»åŠ æ¢¯åº¦è£å‰ª
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# 3. æ£€æŸ¥è¾“å…¥æ•°æ®
print(f"Input range: [{x.min()}, {x.max()}]")
# åº”è¯¥æ ‡å‡†åŒ–åˆ° [-1, 1] æˆ– [0, 1]

# 4. ä½¿ç”¨æ›´ç¨³å®šçš„åˆå§‹åŒ–
def init_weights(m):
    if isinstance(m, nn.Linear):
        torch.nn.init.xavier_uniform_(m.weight)
        if m.bias is not None:
            torch.nn.init.zeros_(m.bias)

model.apply(init_weights)
```

### é—®é¢˜ 4: GPU å†…å­˜ä¸è¶³ï¼ˆOOMï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# 1. å‡å° batch size
batch_size = 32  # ä» 128 é™åˆ° 32

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4

# 3. ä½¿ç”¨æ··åˆç²¾åº¦
from torch.cuda.amp import autocast
with autocast():
    output = model(x)

# 4. å‡å°æ¨¡å‹å°ºå¯¸
model = VisionTransformer(
    embed_dim=128,      # ä» 512 é™åˆ° 128
    num_layers=4,       # ä» 6 é™åˆ° 4
    ...
)

# 5. æ¸…ç†ç¼“å­˜
torch.cuda.empty_cache()
```

### é—®é¢˜ 5: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# 1. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆ1.5-2x åŠ é€Ÿï¼‰
from torch.cuda.amp import autocast, GradScaler

# 2. å¢å¤§ batch sizeï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰
batch_size = 256  # æ›´å¤§çš„ batch

# 3. ä½¿ç”¨æ›´å¤š workers
train_loader = DataLoader(dataset, batch_size=128, num_workers=4)

# 4. Pin memory
train_loader = DataLoader(dataset, batch_size=128, pin_memory=True)

# 5. å‡å°æ¨¡å‹å°ºå¯¸æˆ–å±‚æ•°
model = VisionTransformer(..., num_layers=4)  # ä» 6 é™åˆ° 4
```

---

## ğŸ“‹ å®Œæ•´è®­ç»ƒé…ç½®ç¤ºä¾‹

### ç¤ºä¾‹ 1: CIFAR-10 å°æ•°æ®é›†ï¼ˆæ¨èå¼€å§‹ï¼‰

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from cs231n.classifiers.transformer import VisionTransformer

# ===== 1. æ•°æ®å‡†å¤‡ =====
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

val_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = datasets.CIFAR10(root='./data', train=True,
                                 download=True, transform=train_transform)
val_dataset = datasets.CIFAR10(root='./data', train=False,
                               transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=128,
                         shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=256,
                       shuffle=False, num_workers=2, pin_memory=True)

# ===== 2. æ¨¡å‹é…ç½® =====
model = VisionTransformer(
    img_size=32,
    patch_size=8,
    in_channels=3,
    embed_dim=256,          # ä¸­ç­‰å°ºå¯¸
    num_layers=6,
    num_heads=8,
    dim_feedforward=1024,
    num_classes=10,
    dropout=0.1
).cuda()

print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

# ===== 3. è®­ç»ƒé…ç½® =====
num_epochs = 100
base_lr = 1e-3
weight_decay = 1e-4

# ä¼˜åŒ–å™¨ï¼šAdamW
param_groups = get_parameter_groups(model, weight_decay)
optimizer = torch.optim.AdamW(param_groups, lr=base_lr)

# å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šCosine Annealing with Warmup
scheduler = WarmupScheduler(
    optimizer,
    warmup_epochs=5,
    total_epochs=num_epochs,
    base_lr=base_lr,
    warmup_lr=1e-6
)

# æŸå¤±å‡½æ•°ï¼šå¸¦ Label Smoothing
criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

# Early Stopping
early_stopping = EarlyStopping(patience=15)

# æ··åˆç²¾åº¦
scaler = GradScaler()

# ===== 4. è®­ç»ƒå¾ªç¯ =====
best_val_acc = 0
train_losses, val_losses = [], []
train_accs, val_accs = [], []

for epoch in range(num_epochs):
    # æ›´æ–°å­¦ä¹ ç‡
    lr = scheduler.step()

    # ===== è®­ç»ƒ =====
    model.train()
    train_loss = 0
    train_correct = 0
    train_total = 0

    for x, y in train_loader:
        x, y = x.cuda(), y.cuda()

        optimizer.zero_grad()

        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with autocast():
            output = model(x)
            loss = criterion(output, y)

        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()

        # æ¢¯åº¦è£å‰ª
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        # æ›´æ–°æƒé‡
        scaler.step(optimizer)
        scaler.update()

        # ç»Ÿè®¡
        train_loss += loss.item() * x.size(0)
        pred = output.argmax(dim=1)
        train_correct += (pred == y).sum().item()
        train_total += x.size(0)

    train_loss /= train_total
    train_acc = train_correct / train_total

    # ===== éªŒè¯ =====
    model.eval()
    val_loss = 0
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for x, y in val_loader:
            x, y = x.cuda(), y.cuda()
            output = model(x)
            loss = criterion(output, y)

            val_loss += loss.item() * x.size(0)
            pred = output.argmax(dim=1)
            val_correct += (pred == y).sum().item()
            val_total += x.size(0)

    val_loss /= val_total
    val_acc = val_correct / val_total

    # è®°å½•
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_acc)
    val_accs.append(val_acc)

    # æ‰“å°
    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"LR: {lr:.6f} | "
          f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'best_vit_model.pt')
        print(f"âœ“ Best model saved! Val Acc: {val_acc:.4f}")

    # Early Stopping
    early_stopping(val_acc, model)
    if early_stopping.early_stop:
        print("Early stopping triggered!")
        break

# ===== 5. ç»˜åˆ¶å­¦ä¹ æ›²çº¿ =====
plot_learning_curves(train_losses, val_losses, train_accs, val_accs)

print(f"\nTraining complete! Best validation accuracy: {best_val_acc:.4f}")
```

### ç¤ºä¾‹ 2: å¿«é€Ÿå®éªŒé…ç½®

```python
# ç”¨äºå¿«é€Ÿè°ƒå‚å’Œå®éªŒ
model = VisionTransformer(
    img_size=32,
    patch_size=8,
    embed_dim=128,          # å°æ¨¡å‹
    num_layers=4,           # å°‘å±‚æ•°
    num_heads=4,
    dim_feedforward=512,
    num_classes=10,
    dropout=0.1
)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
num_epochs = 50  # æ›´å°‘ epochs

# è®­ç»ƒé€Ÿåº¦ï¼š~2-3x å¿«äºæ ‡å‡†é…ç½®
```

---

## ğŸ“Š è¶…å‚æ•°è°ƒä¼˜æµç¨‹å›¾

```
å¼€å§‹
  â†“
[1] è¿‡æ‹Ÿåˆä¸€ä¸ª batch
  â”œâ”€ âœ“ æˆåŠŸ â†’ ç»§ç»­
  â””â”€ âœ— å¤±è´¥ â†’ ä¿®å¤å®ç°bugï¼Œè¿”å›æ­¥éª¤1
  â†“
[2] é€‰æ‹©åŸºç¡€é…ç½®
  â”œâ”€ å°æ¨¡å‹ï¼šembed_dim=128, layers=4
  â”œâ”€ ä¸­æ¨¡å‹ï¼šembed_dim=256, layers=6
  â””â”€ å¤§æ¨¡å‹ï¼šembed_dim=512, layers=12
  â†“
[3] è°ƒæ•´å­¦ä¹ ç‡
  â”œâ”€ ä» 1e-3 å¼€å§‹
  â”œâ”€ è§‚å¯Ÿ loss æ›²çº¿
  â”œâ”€ å¤ªé«˜ï¼šéœ‡è¡ â†’ é™ä½
  â””â”€ å¤ªä½ï¼šæ”¶æ•›æ…¢ â†’ å¢å¤§
  â†“
[4] æ£€æŸ¥è¿‡æ‹Ÿåˆç¨‹åº¦
  â”œâ”€ ä¸¥é‡è¿‡æ‹Ÿåˆ â†’ å¢åŠ æ­£åˆ™åŒ–
  â”‚   â”œâ”€ å¢å¤§ dropout (0.1 â†’ 0.3)
  â”‚   â”œâ”€ å¢å¤§ weight_decay (1e-4 â†’ 1e-3)
  â”‚   â””â”€ å¢åŠ æ•°æ®å¢å¼º
  â”œâ”€ æ¬ æ‹Ÿåˆ â†’ å‡å°‘æ­£åˆ™åŒ– / å¢å¤§æ¨¡å‹
  â””â”€ è½»å¾®è¿‡æ‹Ÿåˆ â†’ æ­£å¸¸ï¼Œå¾®è°ƒå³å¯
  â†“
[5] æ·»åŠ è®­ç»ƒæŠ€å·§
  â”œâ”€ å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆCosine Annealingï¼‰
  â”œâ”€ Warmupï¼ˆå¤§æ¨¡å‹å¿…éœ€ï¼‰
  â”œâ”€ Label Smoothing
  â”œâ”€ Mixup/Cutmixï¼ˆå¯é€‰ï¼‰
  â””â”€ æ··åˆç²¾åº¦è®­ç»ƒï¼ˆåŠ é€Ÿï¼‰
  â†“
[6] æœ€ç»ˆè°ƒä¼˜
  â”œâ”€ ç½‘æ ¼æœç´¢å…³é”®è¶…å‚æ•°
  â”œâ”€ å¤šæ¬¡è¿è¡Œå–å¹³å‡
  â””â”€ é€‰æ‹©æœ€ä½³é…ç½®
  â†“
å®Œæˆï¼
```

---

## ğŸ¯ æ€»ç»“ï¼šè°ƒä¼˜ä¼˜å…ˆçº§

### å¿…é¡»åš âœ…
1. **è¿‡æ‹Ÿåˆæµ‹è¯•** - éªŒè¯å®ç°æ­£ç¡®
2. **å­¦ä¹ ç‡** - æœ€é‡è¦çš„è¶…å‚æ•°
3. **æ•°æ®å¢å¼º** - ViT çš„å¿…éœ€å“
4. **åŸºç¡€æ­£åˆ™åŒ–** - Dropout + Weight Decay

### åº”è¯¥åš â­
5. **å­¦ä¹ ç‡è°ƒåº¦** - Cosine Annealing
6. **æ¢¯åº¦è£å‰ª** - é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
7. **Early Stopping** - èŠ‚çœæ—¶é—´
8. **æ··åˆç²¾åº¦** - åŠ é€Ÿè®­ç»ƒ

### å¯é€‰åš ğŸ’¡
9. **Warmup** - å¤§æ¨¡å‹æœ‰å¸®åŠ©
10. **Label Smoothing** - æå‡æ³›åŒ–
11. **Mixup/Cutmix** - é«˜çº§å¢å¼º
12. **Stochastic Depth** - æ·±å±‚ç½‘ç»œ

---

**è®°ä½**ï¼šæ²¡æœ‰ä¸‡èƒ½çš„é…ç½®ï¼Œéœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†å’Œä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚ä»ç®€å•é…ç½®å¼€å§‹ï¼Œé€æ­¥æ·»åŠ å¤æ‚æŠ€å·§ï¼

ğŸ“– ç›¸å…³æ–‡æ¡£ï¼š
- `transformer_residual_pattern.md` - åŸç†è¯¦è§£
- `transformer_quick_reference.md` - å¿«é€Ÿå‚è€ƒ
