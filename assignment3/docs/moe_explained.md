# Mixture of Experts (MoE) è¯¦è§£

## ğŸ“‹ ç›®å½•

1. [åŸºæœ¬æ¦‚å¿µ](#åŸºæœ¬æ¦‚å¿µ)
2. [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
3. [æ¶æ„è¯¦è§£](#æ¶æ„è¯¦è§£)
4. [å·¥ä½œåŸç†](#å·¥ä½œåŸç†)
5. [æ•°å­¦å…¬å¼](#æ•°å­¦å…¬å¼)
6. [MoE in Transformer](#moe-in-transformer)
7. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
8. [è®­ç»ƒæŠ€å·§](#è®­ç»ƒæŠ€å·§)
9. [MoE å˜ä½“](#moe-å˜ä½“)
10. [ä¼˜ç¼ºç‚¹åˆ†æ](#ä¼˜ç¼ºç‚¹åˆ†æ)
11. [å®é™…åº”ç”¨](#å®é™…åº”ç”¨)

---

## ğŸ¯ åŸºæœ¬æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ MoEï¼Ÿ

**Mixture of Experts (æ··åˆä¸“å®¶æ¨¡å‹)** æ˜¯ä¸€ç§æ¨¡å‹æ¶æ„ï¼Œå®ƒå°†ä¸€ä¸ªå¤§å‹ç½‘ç»œåˆ†è§£ä¸ºå¤šä¸ªè¾ƒå°çš„"ä¸“å®¶"ç½‘ç»œï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ª"é—¨æ§ç½‘ç»œ"(Gating Network) æ¥å†³å®šå“ªäº›ä¸“å®¶åº”è¯¥å¤„ç†å“ªäº›è¾“å…¥ã€‚

```
ä¼ ç»Ÿ FFN:
  Input â†’ [å¤§å‹ FFN] â†’ Output
          æ‰€æœ‰å‚æ•°éƒ½æ¿€æ´»

MoE:
  Input â†’ [Gating] â†’ é€‰æ‹©ä¸“å®¶ â†’ [Expert 1, Expert 3] â†’ Output
                                  åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶
```

### ä¸ºä»€ä¹ˆéœ€è¦ MoEï¼Ÿ

**æ ¸å¿ƒé—®é¢˜**ï¼šå¦‚ä½•åœ¨ä¸å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹å¢åŠ æ¨¡å‹å®¹é‡ï¼Ÿ

```
ä¼ ç»Ÿæ–¹æ³•æ‰©å±•æ¨¡å‹:
  å‚æ•° Ã— 2 â†’ è®¡ç®— Ã— 2 â†’ æˆæœ¬ Ã— 2  âŒ

MoE æ–¹æ³•:
  å‚æ•° Ã— 10 â†’ è®¡ç®— Ã— 1.2 â†’ æˆæœ¬ Ã— 1.2  âœ“
  â†‘              â†‘
  å¤§å®¹é‡        ç¨€ç–æ¿€æ´»
```

**å…³é”®ä¼˜åŠ¿**ï¼š

| æŒ‡æ ‡ | ä¼ ç»Ÿæ¨¡å‹ | MoE æ¨¡å‹ |
|------|---------|---------|
| **æ€»å‚æ•°** | 1B | 10B (10Ã—) |
| **æ¿€æ´»å‚æ•°** | 1B | 1.2B (1.2Ã—) |
| **è®¡ç®—æˆæœ¬** | 100% | ~120% |
| **æ¨¡å‹å®¹é‡** | æ ‡å‡† | 10Ã— å®¹é‡ |

---

## ğŸ’¡ æ ¸å¿ƒæ€æƒ³

### ä¸“ä¸šåŒ– (Specialization)

```
ç±»æ¯”ï¼šåŒ»é™¢çš„ä¸“ç§‘åŒ»ç”Ÿ

æ™®é€šåŒ»é™¢ (ä¼ ç»Ÿæ¨¡å‹):
  å…¨ç§‘åŒ»ç”Ÿ â†’ å¤„ç†æ‰€æœ‰ç—…äºº
  ä¼˜ç‚¹: çµæ´»
  ç¼ºç‚¹: ä¸å¤Ÿä¸“ä¸š

ä¸“ç§‘åŒ»é™¢ (MoE):
  å¿ƒè„ç§‘ â†’ å¤„ç†å¿ƒè„ç—…äºº  } æ¯ä¸ªä¸“å®¶ä¸“æ³¨äº
  éª¨ç§‘   â†’ å¤„ç†éª¨æŠ˜ç—…äºº  } ç‰¹å®šç±»å‹çš„è¾“å…¥
  å„¿ç§‘   â†’ å¤„ç†å„¿ç«¥ç—…äºº  }
  æŒ‚å·å¤„ â†’ åˆ†é…ç—…äººåˆ°æ­£ç¡®ç§‘å®¤ (Gating)
```

### æ¡ä»¶è®¡ç®— (Conditional Computation)

**ä¼ ç»Ÿæ¨¡å‹**ï¼š
```
æ‰€æœ‰å‚æ•°å¯¹æ‰€æœ‰è¾“å…¥éƒ½æ¿€æ´»
  Input_1 â†’ [All Parameters] â†’ Output_1
  Input_2 â†’ [All Parameters] â†’ Output_2
  Input_3 â†’ [All Parameters] â†’ Output_3

æµªè´¹: ä¸æ˜¯æ‰€æœ‰å‚æ•°å¯¹æ‰€æœ‰è¾“å…¥éƒ½æœ‰ç”¨
```

**MoE**ï¼š
```
æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©å‚æ•°å­é›†
  Input_1 â†’ [Expert 1, Expert 3] â†’ Output_1
  Input_2 â†’ [Expert 2, Expert 5] â†’ Output_2
  Input_3 â†’ [Expert 1, Expert 4] â†’ Output_3

é«˜æ•ˆ: æ¯ä¸ªè¾“å…¥åªä½¿ç”¨ç›¸å…³çš„ä¸“å®¶
```

### ç¨€ç–æ¿€æ´» (Sparse Activation)

```
æ¨¡å‹æ€»å‚æ•°: 8 ä¸ª Experts Ã— 512M = 4B å‚æ•°
æ¯æ¬¡æ¿€æ´»: Top-2 Experts = 1B å‚æ•°

ç¨€ç–åº¦: 1B / 4B = 25% (åªç”¨ 25% çš„å‚æ•°)

ç»“æœ:
  âœ“ 4B å‚æ•°çš„æ¨¡å‹å®¹é‡
  âœ“ 1B å‚æ•°çš„è®¡ç®—æˆæœ¬
  = æœ€ä½³æ€§ä»·æ¯”!
```

---

## ğŸ—ï¸ æ¶æ„è¯¦è§£

### MoE Layer ç»“æ„

```
         Input x (N, L, D)
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                   â†“
[Gating Network]    [Expert Networks]
    â†“                   â”‚
Router Scores      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
    â†“              â†“         â†“    â†“    â†“
Top-K Selection   Eâ‚        Eâ‚‚   Eâ‚ƒ  ...  Eâ‚™
    â†“              â”‚         â”‚    â”‚    â”‚
Weights w       Output    Output Output
    â†“              â†“         â†“    â†“    â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Weighted Combination
                     â†“
              Output (N, L, D)
```

### ç»„ä»¶è¯¦è§£

#### 1. Gating Network (Router)

**ä½œç”¨**: ä¸ºæ¯ä¸ªè¾“å…¥å†³å®šåº”è¯¥ä½¿ç”¨å“ªäº›ä¸“å®¶ã€‚

```python
class GatingNetwork(nn.Module):
    def __init__(self, input_dim, num_experts):
        super().__init__()
        self.gate = nn.Linear(input_dim, num_experts)

    def forward(self, x):
        # x: (N, L, D)
        gate_logits = self.gate(x)  # (N, L, num_experts)
        return gate_logits
```

**å¯è§†åŒ–**ï¼š
```
Input Token: [0.5, -0.2, 0.8, ..., 0.3]  (D=128)
      â†“ Linear(128, num_experts=8)
Gate Logits: [2.3, 0.5, -1.2, 1.8, 0.2, -0.5, 1.5, 0.9]
              Eâ‚   Eâ‚‚   Eâ‚ƒ    Eâ‚„   Eâ‚…   Eâ‚†    Eâ‚‡   Eâ‚ˆ
              â†‘                â†‘                â†‘
           æœ€é«˜åˆ†            æ¬¡é«˜åˆ†          ç¬¬ä¸‰é«˜åˆ†

Top-2 Selection â†’ Eâ‚ (2.3), Eâ‚„ (1.8)
```

#### 2. Expert Networks

**ä½œç”¨**: ç‹¬ç«‹çš„ FFNï¼Œæ¯ä¸ªä¸“å®¶ä¸“é—¨å¤„ç†æŸç±»è¾“å…¥ã€‚

```python
class Expert(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, input_dim)
        self.activation = nn.GELU()

    def forward(self, x):
        # x: (num_tokens, D)
        h = self.fc1(x)           # (num_tokens, hidden_dim)
        h = self.activation(h)
        output = self.fc2(h)      # (num_tokens, D)
        return output
```

**ä¸“å®¶ä¸“ä¸šåŒ–ç¤ºä¾‹**ï¼š
```
å‡è®¾ 8 ä¸ªä¸“å®¶åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„åˆ†å·¥:

Expert 1: å¤„ç†åè¯çŸ­è¯­
  "the cat" â†’ é«˜æ¿€æ´»
  "running fast" â†’ ä½æ¿€æ´»

Expert 2: å¤„ç†åŠ¨è¯çŸ­è¯­
  "running fast" â†’ é«˜æ¿€æ´»
  "the cat" â†’ ä½æ¿€æ´»

Expert 3: å¤„ç†æ•°å­—å’Œæ—¥æœŸ
  "2024" â†’ é«˜æ¿€æ´»
  "beautiful" â†’ ä½æ¿€æ´»

...

è‡ªåŠ¨å­¦ä¹ çš„ä¸“ä¸šåŒ–!
```

#### 3. Top-K Gating

**ä½œç”¨**: åªé€‰æ‹©å¾—åˆ†æœ€é«˜çš„ K ä¸ªä¸“å®¶ã€‚

```python
def top_k_gating(gate_logits, k=2):
    # gate_logits: (N, L, num_experts)

    # 1. Softmax å½’ä¸€åŒ–
    gate_probs = F.softmax(gate_logits, dim=-1)

    # 2. é€‰æ‹© Top-K
    topk_values, topk_indices = torch.topk(gate_probs, k, dim=-1)

    # 3. é‡æ–°å½’ä¸€åŒ– (åªå¯¹é€‰ä¸­çš„ä¸“å®¶)
    topk_values = topk_values / topk_values.sum(dim=-1, keepdim=True)

    return topk_values, topk_indices
```

**å¯è§†åŒ–è¿‡ç¨‹**ï¼š
```
Gate Probabilities (softmax å):
  [0.52, 0.11, 0.02, 0.31, 0.06, 0.02, 0.23, 0.10]
   Eâ‚    Eâ‚‚    Eâ‚ƒ    Eâ‚„    Eâ‚…    Eâ‚†    Eâ‚‡    Eâ‚ˆ

Top-2 Selection:
  Selected: Eâ‚ (0.52), Eâ‚„ (0.31)
  Others:   éƒ½è®¾ä¸º 0

Renormalize:
  Eâ‚: 0.52 / (0.52 + 0.31) = 0.63
  Eâ‚„: 0.31 / (0.52 + 0.31) = 0.37
  Final: [0.63, 0, 0, 0.37, 0, 0, 0, 0]
```

---

## âš™ï¸ å·¥ä½œåŸç†

### å®Œæ•´å‰å‘ä¼ æ’­

#### Step 1: è®¡ç®— Gate Scores

```
Input: (N, L, D) = (2, 16, 128)
       â†“ Gating Network: Linear(128, 8)
Gate Logits: (2, 16, 8)
       â†“ Softmax
Gate Probs: (2, 16, 8)
```

**ç¤ºä¾‹ (Batch 0, Token 0)**:
```
Input Vector: [0.5, -0.2, ..., 0.3]  (128ç»´)
       â†“
Gate Logits: [2.3, 0.5, -1.2, 1.8, 0.2, -0.5, 1.5, 0.9]
       â†“ Softmax
Gate Probs: [0.52, 0.11, 0.02, 0.31, 0.06, 0.02, 0.23, 0.10]
```

#### Step 2: Top-K é€‰æ‹©

```
Gate Probs: (2, 16, 8)
       â†“ Top-2
Indices: (2, 16, 2)  â† æ¯ä¸ª token é€‰ä¸­çš„ 2 ä¸ªä¸“å®¶
Weights: (2, 16, 2)  â† å¯¹åº”çš„æƒé‡
```

**ç¤ºä¾‹**:
```
Token 0:
  Top-2 Indices: [0, 3]  â† Expert 1 å’Œ Expert 4
  Top-2 Weights: [0.63, 0.37]

Token 1:
  Top-2 Indices: [1, 6]  â† Expert 2 å’Œ Expert 7
  Top-2 Weights: [0.55, 0.45]

...
```

#### Step 3: åˆ†é… Tokens åˆ° Experts

```python
# ä¸ºæ¯ä¸ªä¸“å®¶æ”¶é›†åˆ†é…ç»™å®ƒçš„ tokens
expert_inputs = {}
for expert_id in range(num_experts):
    # æ‰¾åˆ°æ‰€æœ‰é€‰æ‹©äº†è¿™ä¸ªä¸“å®¶çš„ tokens
    mask = (top_indices == expert_id)
    expert_inputs[expert_id] = x[mask]
```

**å¯è§†åŒ–åˆ†é…**:
```
Expert 0 (Eâ‚):
  Token 0 (weight 0.63)
  Token 5 (weight 0.41)
  Token 12 (weight 0.58)
  â†’ è¾“å…¥: (3, 128)  â† 3 ä¸ª tokens

Expert 1 (Eâ‚‚):
  Token 1 (weight 0.55)
  Token 3 (weight 0.72)
  â†’ è¾“å…¥: (2, 128)  â† 2 ä¸ª tokens

Expert 2 (Eâ‚ƒ):
  (æ²¡æœ‰ tokens åˆ†é…)
  â†’ è¾“å…¥: (0, 128)  â† ç©º! (è´Ÿè½½ä¸å‡è¡¡)

...
```

#### Step 4: Expert è®¡ç®—

```python
expert_outputs = {}
for expert_id, expert in enumerate(experts):
    if len(expert_inputs[expert_id]) > 0:
        expert_outputs[expert_id] = expert(expert_inputs[expert_id])
```

**è®¡ç®—è¿‡ç¨‹**:
```
Expert 0 å¤„ç† 3 ä¸ª tokens:
  Input: (3, 128)
     â†“ FC1: 128 â†’ 512
  Hidden: (3, 512)
     â†“ GELU
     â†“ FC2: 512 â†’ 128
  Output: (3, 128)

Expert 1 å¤„ç† 2 ä¸ª tokens:
  Input: (2, 128)
     â†“ FFN
  Output: (2, 128)

Expert 2: è·³è¿‡ (æ— è¾“å…¥)
```

#### Step 5: åŠ æƒç»„åˆ

```python
# å¯¹äºæ¯ä¸ª tokenï¼Œç»„åˆå…¶é€‰ä¸­çš„ä¸“å®¶è¾“å‡º
output = torch.zeros_like(x)
for token_idx in range(num_tokens):
    for k in range(top_k):
        expert_id = top_indices[token_idx, k]
        weight = top_weights[token_idx, k]
        output[token_idx] += weight * expert_outputs[expert_id][...]
```

**ç¤ºä¾‹ (Token 0)**:
```
Token 0 é€‰æ‹©:
  Expert 0 (weight 0.63): outputâ‚€ = [0.2, -0.1, 0.5, ...]
  Expert 3 (weight 0.37): outputâ‚ƒ = [-0.3, 0.4, 0.2, ...]

ç»„åˆ:
  final = 0.63 * outputâ‚€ + 0.37 * outputâ‚ƒ
        = 0.63 * [0.2, -0.1, 0.5, ...] + 0.37 * [-0.3, 0.4, 0.2, ...]
        = [0.015, 0.085, 0.389, ...]
```

### å®Œæ•´æ•°æ®æµç¤ºä¾‹

```
é…ç½®:
  num_experts = 8
  top_k = 2
  input_dim = 128
  hidden_dim = 512

è¾“å…¥: (N, L, D) = (2, 16, 128)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gating Network                                         â”‚
â”‚   Linear(128, 8)                                       â”‚
â”‚   Softmax                                              â”‚
â”‚   Output: (2, 16, 8) - æ¯ä¸ª token å¯¹ 8 ä¸ªä¸“å®¶çš„æ¦‚ç‡    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Top-2 Selection                                        â”‚
â”‚   é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ 2 ä¸ªä¸“å®¶                               â”‚
â”‚   Indices: (2, 16, 2)                                  â”‚
â”‚   Weights: (2, 16, 2)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Expert Computation (å¹¶è¡Œ)                              â”‚
â”‚   Expert 0: å¤„ç† 5 ä¸ª tokens  â”€â”                       â”‚
â”‚   Expert 1: å¤„ç† 3 ä¸ª tokens   â”‚                       â”‚
â”‚   Expert 2: å¤„ç† 0 ä¸ª tokens   â”‚ å¹¶è¡Œè®¡ç®—               â”‚
â”‚   Expert 3: å¤„ç† 8 ä¸ª tokens   â”‚                       â”‚
â”‚   Expert 4: å¤„ç† 4 ä¸ª tokens   â”‚                       â”‚
â”‚   Expert 5: å¤„ç† 2 ä¸ª tokens   â”‚                       â”‚
â”‚   Expert 6: å¤„ç† 6 ä¸ª tokens   â”‚                       â”‚
â”‚   Expert 7: å¤„ç† 4 ä¸ª tokens  â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Weighted Combination                                   â”‚
â”‚   æ¯ä¸ª token ç»„åˆå…¶é€‰ä¸­çš„ 2 ä¸ªä¸“å®¶è¾“å‡º                  â”‚
â”‚   ä½¿ç”¨ Top-2 æƒé‡åŠ æƒå¹³å‡                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
è¾“å‡º: (2, 16, 128)
```

---

## ğŸ“ æ•°å­¦å…¬å¼

### Gating å‡½æ•°

ç»™å®šè¾“å…¥ $x \in \mathbb{R}^d$ï¼Œæœ‰ $n$ ä¸ªä¸“å®¶ $\{E_1, E_2, \ldots, E_n\}$ã€‚

#### 1. Gate Logits

```
g(x) = W_g x + b_g

å…¶ä¸­:
  W_g âˆˆ â„^{nÃ—d}  (gate æƒé‡)
  b_g âˆˆ â„^n      (gate åç½®)
  g(x) âˆˆ â„^n     (æ¯ä¸ªä¸“å®¶çš„ logit)
```

#### 2. Gate Probabilities (Softmax)

```
p_i(x) = exp(g_i(x)) / Î£â±¼ exp(gâ±¼(x))

å…¶ä¸­:
  p_i(x): é€‰æ‹©ä¸“å®¶ i çš„æ¦‚ç‡
  Î£áµ¢ p_i(x) = 1  (æ¦‚ç‡å’Œä¸º1)
```

#### 3. Top-K Selection

```
K = {iâ‚, iâ‚‚, ..., iâ‚–}  å…¶ä¸­ p_{iâ‚} â‰¥ p_{iâ‚‚} â‰¥ ... â‰¥ p_{iâ‚–}

ç¨€ç– gate:
  pÌƒ_i(x) = { p_i(x) / Î£â±¼âˆˆK p_j(x)   if i âˆˆ K
            { 0                       otherwise
```

#### 4. MoE è¾“å‡º

```
MoE(x) = Î£áµ¢âˆˆK pÌƒ_i(x) Â· E_i(x)

å±•å¼€:
  MoE(x) = pÌƒ_{iâ‚}(x)Â·E_{iâ‚}(x) + pÌƒ_{iâ‚‚}(x)Â·E_{iâ‚‚}(x) + ... + pÌƒ_{iâ‚–}(x)Â·E_{iâ‚–}(x)
```

### è´Ÿè½½å‡è¡¡æŸå¤±

**é—®é¢˜**: æ‰€æœ‰ tokens éƒ½é€‰æ‹©ç›¸åŒçš„å‡ ä¸ªä¸“å®¶ â†’ å…¶ä»–ä¸“å®¶æµªè´¹

**è§£å†³**: æ·»åŠ è´Ÿè½½å‡è¡¡æŸå¤±ï¼Œé¼“åŠ±å‡åŒ€ä½¿ç”¨ä¸“å®¶ã€‚

#### Auxiliary Loss (è¾…åŠ©æŸå¤±)

```
L_aux = Î± Â· Î£áµ¢ fáµ¢ Â· Páµ¢

å…¶ä¸­:
  fáµ¢ = (åˆ†é…ç»™ä¸“å®¶ i çš„ tokens æ•°) / (æ€» tokens æ•°)
  Páµ¢ = Î£â‚“ p_i(x) / (æ€» tokens æ•°)  (ä¸“å®¶ i çš„å¹³å‡æ¦‚ç‡)
  Î±: æŸå¤±æƒé‡ (é€šå¸¸ 0.01)
```

**ç›´è§‰**:
- å¦‚æœä¸“å®¶ i å¾ˆå°‘è¢«é€‰ä¸­ ($f_i$ å°) ä½†æ¦‚ç‡é«˜ ($P_i$ å¤§) â†’ æŸå¤±é«˜
- é¼“åŠ±æ¦‚ç‡å’Œå®é™…åˆ†é…ä¸€è‡´

**ç¤ºä¾‹**:
```
Expert 0:
  fâ‚€ = 100/1000 = 0.10  (10% tokens)
  Pâ‚€ = 0.15             (å¹³å‡ 15% æ¦‚ç‡)
  è´¡çŒ®: 0.10 Ã— 0.15 = 0.015

Expert 1:
  fâ‚ = 300/1000 = 0.30  (30% tokens) â† è¿‡åº¦ä½¿ç”¨
  Pâ‚ = 0.25             (å¹³å‡ 25% æ¦‚ç‡)
  è´¡çŒ®: 0.30 Ã— 0.25 = 0.075  â† é«˜æŸå¤±

ç†æƒ³æƒ…å†µ (å‡åŒ€):
  æ¯ä¸ªä¸“å®¶: fáµ¢ = Páµ¢ = 1/num_experts
  æœ€å°åŒ– L_aux
```

### æ€»æŸå¤±å‡½æ•°

```
L_total = L_task + Î±Â·L_aux + Î²Â·L_z

å…¶ä¸­:
  L_task: ä¸»ä»»åŠ¡æŸå¤± (å¦‚ CrossEntropy)
  L_aux:  è´Ÿè½½å‡è¡¡æŸå¤±
  L_z:    é‡è¦æ€§æŸå¤± (å¯é€‰)
  Î±, Î²:   æƒé‡ç³»æ•°
```

---

## ğŸ”„ MoE in Transformer

### æ›¿æ¢ FFN å±‚

**æ ‡å‡† Transformer**:
```
Input
  â†“
Multi-Head Attention
  â†“ + Residual + Norm
  â†“
Feedforward Network  â† æ›¿æ¢ä¸º MoE!
  â†“ + Residual + Norm
Output
```

**MoE Transformer**:
```
Input
  â†“
Multi-Head Attention
  â†“ + Residual + Norm
  â†“
MoE Layer
  â”œâ”€ Gating Network
  â”œâ”€ Expert 1 (FFN)
  â”œâ”€ Expert 2 (FFN)
  â”œâ”€ ...
  â””â”€ Expert 8 (FFN)
  â†“ + Residual + Norm
Output
```

### MoE Transformer Layer å®ç°

```python
class MoETransformerLayer(nn.Module):
    def __init__(self, d_model, num_heads, num_experts, expert_capacity,
                 top_k=2, dropout=0.1):
        super().__init__()

        # Multi-Head Attention (æ ‡å‡†)
        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.norm1 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)

        # MoE Layer (æ›¿æ¢ FFN)
        self.moe = MoELayer(
            d_model=d_model,
            num_experts=num_experts,
            expert_capacity=expert_capacity,
            top_k=top_k
        )
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout2 = nn.Dropout(dropout)

    def forward(self, x, mask=None):
        # Self-Attention sublayer
        shortcut = x
        x = self.self_attn(x, x, x, mask)
        x = self.dropout1(x)
        x = x + shortcut
        x = self.norm1(x)

        # MoE sublayer
        shortcut = x
        x, aux_loss = self.moe(x)  # MoE è¿”å›è¾“å‡ºå’Œè¾…åŠ©æŸå¤±
        x = self.dropout2(x)
        x = x + shortcut
        x = self.norm2(x)

        return x, aux_loss
```

### MoE Layer å®ç°

```python
class MoELayer(nn.Module):
    def __init__(self, d_model, num_experts=8, expert_capacity=None,
                 top_k=2, hidden_dim=None):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k

        if hidden_dim is None:
            hidden_dim = 4 * d_model

        # Gating network
        self.gate = nn.Linear(d_model, num_experts, bias=False)

        # Expert networks
        self.experts = nn.ModuleList([
            Expert(d_model, hidden_dim)
            for _ in range(num_experts)
        ])

    def forward(self, x):
        """
        Args:
            x: (batch_size, seq_len, d_model)
        Returns:
            output: (batch_size, seq_len, d_model)
            aux_loss: scalar
        """
        batch_size, seq_len, d_model = x.shape

        # Flatten batch and sequence dimensions
        x_flat = x.view(-1, d_model)  # (B*L, D)

        # 1. Compute gate scores
        gate_logits = self.gate(x_flat)  # (B*L, num_experts)
        gate_probs = F.softmax(gate_logits, dim=-1)

        # 2. Select top-k experts
        topk_values, topk_indices = torch.topk(
            gate_probs, self.top_k, dim=-1
        )  # (B*L, top_k)

        # Renormalize
        topk_values = topk_values / topk_values.sum(dim=-1, keepdim=True)

        # 3. Prepare for expert computation
        output = torch.zeros_like(x_flat)

        # 4. For each expert, gather its inputs and compute
        for expert_id in range(self.num_experts):
            # Find tokens assigned to this expert
            expert_mask = (topk_indices == expert_id)
            expert_tokens = expert_mask.any(dim=-1)

            if expert_tokens.sum() == 0:
                continue  # Skip if no tokens assigned

            # Get inputs for this expert
            expert_input = x_flat[expert_tokens]  # (num_tokens, D)

            # Compute expert output
            expert_output = self.experts[expert_id](expert_input)

            # Get weights for this expert
            expert_weights = topk_values[expert_mask].unsqueeze(-1)

            # Add weighted output
            output[expert_tokens] += expert_weights * expert_output

        # 5. Compute auxiliary loss (load balancing)
        aux_loss = self._compute_aux_loss(gate_probs)

        # Reshape back
        output = output.view(batch_size, seq_len, d_model)

        return output, aux_loss

    def _compute_aux_loss(self, gate_probs):
        # Auxiliary loss for load balancing
        # L_aux = num_experts * Î£áµ¢ fáµ¢ * Páµ¢

        # fáµ¢: fraction of tokens assigned to expert i
        # Páµ¢: average gate probability for expert i

        # Average probability for each expert
        P = gate_probs.mean(dim=0)  # (num_experts,)

        # Fraction of tokens (based on top-k selection)
        f = (gate_probs > 0).float().mean(dim=0)

        # Auxiliary loss
        aux_loss = self.num_experts * (f * P).sum()

        return aux_loss
```

### Expert ç½‘ç»œå®ç°

```python
class Expert(nn.Module):
    """å•ä¸ªä¸“å®¶ç½‘ç»œ (æ ‡å‡† FFN)"""
    def __init__(self, d_model, hidden_dim, dropout=0.1):
        super().__init__()
        self.fc1 = nn.Linear(d_model, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, d_model)
        self.activation = nn.GELU()
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # x: (num_tokens, d_model)
        h = self.fc1(x)           # (num_tokens, hidden_dim)
        h = self.activation(h)
        h = self.dropout(h)
        output = self.fc2(h)      # (num_tokens, d_model)
        return output
```

### æ•°æ®æµå¯è§†åŒ–

```
Input Sequence: (2, 16, 128)
  Token 0: "The"    â†’ [vecâ‚€]
  Token 1: "cat"    â†’ [vecâ‚]
  Token 2: "sat"    â†’ [vecâ‚‚]
  ...
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gating Network                          â”‚
â”‚   æ¯ä¸ª token è®¡ç®—å¯¹ 8 ä¸ªä¸“å®¶çš„åˆ†æ•°       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Token 0 "The":  [0.5, 0.1, 0.0, 0.3, ...]â”‚
â”‚                  Eâ‚   Eâ‚‚   Eâ‚ƒ   Eâ‚„       â”‚
â”‚                  â†‘              â†‘        â”‚
â”‚                 Top-1         Top-2      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Token 1 "cat":  [0.1, 0.6, 0.2, 0.0, ...]â”‚
â”‚                  Eâ‚   Eâ‚‚   Eâ‚ƒ   Eâ‚„       â”‚
â”‚                       â†‘    â†‘             â”‚
â”‚                     Top-1 Top-2          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Token Routing                           â”‚
â”‚   åˆ†é… tokens åˆ°ä¸“å®¶                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Expert 1: Token 0, Token 5, Token 12   â”‚
â”‚ Expert 2: Token 1, Token 3, Token 8    â”‚
â”‚ Expert 3: Token 1, Token 10            â”‚
â”‚ Expert 4: Token 0, Token 15            â”‚
â”‚ ...                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Expert Computation (å¹¶è¡Œ)               â”‚
â”‚   Expert 1: FFN([vecâ‚€, vecâ‚…, vecâ‚â‚‚])  â”‚
â”‚   Expert 2: FFN([vecâ‚, vecâ‚ƒ, vecâ‚ˆ])   â”‚
â”‚   ...                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Weighted Combination                    â”‚
â”‚   Token 0 = 0.63*Eâ‚(vecâ‚€) + 0.37*Eâ‚„(vecâ‚€)â”‚
â”‚   Token 1 = 0.75*Eâ‚‚(vecâ‚) + 0.25*Eâ‚ƒ(vecâ‚)â”‚
â”‚   ...                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
Output: (2, 16, 128)
```

---

## ğŸ“ è®­ç»ƒæŠ€å·§

### 1. è´Ÿè½½å‡è¡¡

**é—®é¢˜**: æ¨¡å‹å€¾å‘äºåªä½¿ç”¨å°‘æ•°å‡ ä¸ªä¸“å®¶

**è§£å†³æ–¹æ¡ˆ**:

#### A. Auxiliary Loss

```python
# æ·»åŠ è¾…åŠ©æŸå¤±é¼“åŠ±å‡åŒ€åˆ†é…
total_loss = task_loss + 0.01 * aux_loss
```

#### B. Expert Capacity

é™åˆ¶æ¯ä¸ªä¸“å®¶å¤„ç†çš„æœ€å¤§ tokens æ•°ï¼š

```python
class MoEWithCapacity(nn.Module):
    def __init__(self, ..., expert_capacity):
        self.expert_capacity = expert_capacity

    def forward(self, x):
        # ... routing ...

        # Enforce capacity constraint
        for expert_id in range(num_experts):
            expert_tokens = tokens_for_expert[expert_id]
            if len(expert_tokens) > self.expert_capacity:
                # åªå¤„ç†å‰ capacity ä¸ª tokens
                expert_tokens = expert_tokens[:self.expert_capacity]
                # å…¶ä»– tokens æº¢å‡ºï¼Œä½¿ç”¨æ®‹å·®è¿æ¥
```

**å®¹é‡è®¡ç®—**:
```
capacity = (total_tokens / num_experts) * capacity_factor

ç¤ºä¾‹:
  total_tokens = 1000
  num_experts = 8
  capacity_factor = 1.25  (å…è®¸ 25% è¶…è½½)

  capacity = (1000 / 8) * 1.25 = 156 tokens per expert
```

#### C. Random Routing (è®­ç»ƒåˆæœŸ)

```python
# è®­ç»ƒåˆæœŸéšæœºè·¯ç”±ï¼Œé˜²æ­¢æ—©æœŸå´©æºƒ
if training and step < warmup_steps:
    # æ·»åŠ å™ªå£°åˆ° gate logits
    gate_logits = gate_logits + torch.randn_like(gate_logits) * noise_std
```

### 2. ä¸“å®¶åˆå§‹åŒ–

**é‡è¦**: ä¸“å®¶åº”è¯¥åˆå§‹åŒ–å¾—ä¸åŒï¼Œé¿å…å¯¹ç§°æ€§ã€‚

```python
def init_experts(experts):
    for i, expert in enumerate(experts):
        # æ¯ä¸ªä¸“å®¶ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
        torch.manual_seed(i)
        for param in expert.parameters():
            if param.dim() > 1:
                nn.init.xavier_uniform_(param)
```

### 3. Gradient Clipping

MoE è®­ç»ƒå¯èƒ½ä¸ç¨³å®šï¼Œéœ€è¦æ¢¯åº¦è£å‰ªï¼š

```python
# è®­ç»ƒå¾ªç¯
optimizer.zero_grad()
loss.backward()
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
optimizer.step()
```

### 4. å­¦ä¹ ç‡è°ƒæ•´

MoE å¯èƒ½éœ€è¦ä¸åŒçš„å­¦ä¹ ç‡ï¼š

```python
# Gating ç½‘ç»œç”¨è¾ƒå°å­¦ä¹ ç‡
optimizer = torch.optim.Adam([
    {'params': model.experts.parameters(), 'lr': 1e-3},
    {'params': model.gate.parameters(), 'lr': 1e-4}  # æ›´å°
])
```

---

## ğŸ”€ MoE å˜ä½“

### 1. Switch Transformer (Google, 2021)

**æ ¸å¿ƒæ”¹è¿›**: Top-1 è·¯ç”± (åªé€‰æ‹© 1 ä¸ªä¸“å®¶)

```
æ ‡å‡† MoE: Top-2
  æ¯ä¸ª token â†’ 2 ä¸ªä¸“å®¶ â†’ æ›´ç¨³å®šä½†è®¡ç®—å¤š

Switch Transformer: Top-1
  æ¯ä¸ª token â†’ 1 ä¸ªä¸“å®¶ â†’ æ›´å¿«ä½†å¯èƒ½ä¸ç¨³å®š
```

**ä¼˜åŠ¿**:
- æ›´å¿« (å‡å°‘ 50% ä¸“å®¶è®¡ç®—)
- æ›´ç®€å•çš„è·¯ç”±
- å¯æ‰©å±•åˆ°æ›´å¤šä¸“å®¶ (2048 ä¸ª!)

**ä»£ç å·®å¼‚**:
```python
# æ ‡å‡† MoE: Top-2
topk_values, topk_indices = torch.topk(gate_probs, k=2)

# Switch Transformer: Top-1
topk_values, topk_indices = torch.topk(gate_probs, k=1)
```

### 2. Expert Choice Routing (Google, 2022)

**åè½¬è·¯ç”±**: ä¸“å®¶é€‰æ‹© tokensï¼Œè€Œä¸æ˜¯ tokens é€‰æ‹©ä¸“å®¶

```
æ ‡å‡† MoE (Token Choice):
  Token: "æˆ‘è¦é€‰æ‹©å“ªäº›ä¸“å®¶ï¼Ÿ"
  â†’ Top-K ä¸“å®¶

Expert Choice:
  Expert: "æˆ‘è¦å¤„ç†å“ªäº› tokensï¼Ÿ"
  â†’ Top-K tokens
```

**ä¼˜åŠ¿**:
- æ›´å¥½çš„è´Ÿè½½å‡è¡¡ (ä¸“å®¶è‡ªä¸»æ§åˆ¶å®¹é‡)
- é¿å…æº¢å‡ºé—®é¢˜

**ä»£ç æ¦‚å¿µ**:
```python
# Expert Choice Routing
for expert in experts:
    # ä¸“å®¶æŸ¥çœ‹æ‰€æœ‰ tokens çš„ gate scores
    scores = gate_probs[:, expert_id]

    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ capacity ä¸ª tokens
    topk_tokens = torch.topk(scores, k=capacity)

    # åªå¤„ç†è¿™äº› tokens
    expert_output = expert(x[topk_tokens])
```

### 3. Soft MoE (Microsoft, 2023)

**æ ¸å¿ƒæ€æƒ³**: ä¸åšç¡¬é€‰æ‹©ï¼Œæ‰€æœ‰ä¸“å®¶éƒ½å‚ä¸ä½†æƒé‡ä¸åŒ

```
Hard MoE (Top-K):
  é€‰ä¸­çš„ä¸“å®¶: æƒé‡ > 0
  å…¶ä»–ä¸“å®¶:   æƒé‡ = 0

Soft MoE:
  æ‰€æœ‰ä¸“å®¶:   æƒé‡ > 0 (ä½†å·®å¼‚å¾ˆå¤§)
```

**æ•°å­¦**:
```
Hard: y = Î£áµ¢âˆˆTopK w_i * E_i(x)

Soft: y = Î£áµ¢ w_i * E_i(x)  where w_i = softmax(g_i(x))
```

**ä¼˜åŠ¿**:
- æ›´å¹³æ»‘çš„æ¢¯åº¦
- æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§
- ä¸éœ€è¦è´Ÿè½½å‡è¡¡æŸå¤±

**åŠ£åŠ¿**:
- è®¡ç®—æˆæœ¬é«˜ (æ‰€æœ‰ä¸“å®¶éƒ½è®¡ç®—)

### 4. MoE with Shared Experts

**åŠ¨æœº**: æœ‰äº›çŸ¥è¯†æ˜¯é€šç”¨çš„ï¼Œåº”è¯¥è¢«æ‰€æœ‰ tokens ä½¿ç”¨

```
æ ‡å‡† MoE:
  Token â†’ é€‰æ‹©ä¸“å®¶ â†’ è¾“å‡º

MoE with Shared:
  Token â†’ [é€‰æ‹©ä¸“å®¶ + å…±äº«ä¸“å®¶] â†’ è¾“å‡º
```

**æ¶æ„**:
```python
class MoEWithShared(nn.Module):
    def __init__(self, d_model, num_experts, num_shared=2):
        # è·¯ç”±ä¸“å®¶
        self.routed_experts = nn.ModuleList([
            Expert(d_model) for _ in range(num_experts)
        ])

        # å…±äº«ä¸“å®¶ (æ€»æ˜¯æ¿€æ´»)
        self.shared_experts = nn.ModuleList([
            Expert(d_model) for _ in range(num_shared)
        ])

    def forward(self, x):
        # è·¯ç”±ä¸“å®¶è¾“å‡º
        routed_output = moe_routing(x, self.routed_experts)

        # å…±äº«ä¸“å®¶è¾“å‡º
        shared_output = sum(expert(x) for expert in self.shared_experts)

        # ç»„åˆ
        return routed_output + shared_output
```

---

## âš–ï¸ ä¼˜ç¼ºç‚¹åˆ†æ

### âœ… ä¼˜åŠ¿

#### 1. å‚æ•°æ•ˆç‡

```
ä¼ ç»Ÿæ‰©å±•:
  1B â†’ 10B å‚æ•° = 10Ã— è®¡ç®—æˆæœ¬

MoE æ‰©å±•:
  1B â†’ 10B å‚æ•° = 1.2Ã— è®¡ç®—æˆæœ¬

èŠ‚çœ: 8.3Ã— è®¡ç®—ï¼
```

#### 2. ä¸“ä¸šåŒ–å­¦ä¹ 

```
è‡ªåŠ¨å­¦åˆ°çš„ä¸“å®¶åˆ†å·¥:
  Expert 1: å¤„ç†æ•°å­¦é—®é¢˜
  Expert 2: å¤„ç†ä»£ç 
  Expert 3: å¤„ç†å¯¹è¯
  Expert 4: å¤„ç†è¯—æ­Œ
  ...

æ¯”å•ä¸€æ¨¡å‹æ›´ä¸“ä¸š!
```

#### 3. å¯æ‰©å±•æ€§

```
çº¿æ€§æ‰©å±•:
  8 experts  â†’ æˆæœ¬ Ã— 1.2
  64 experts â†’ æˆæœ¬ Ã— 1.5
  512 experts â†’ æˆæœ¬ Ã— 2

æ¯”å¯†é›†æ¨¡å‹ä¾¿å®œå¾—å¤š!
```

#### 4. æ¡ä»¶è®¡ç®—

```
ç®€å•è¾“å…¥ â†’ æ¿€æ´»å°‘æ•°ä¸“å®¶
å¤æ‚è¾“å…¥ â†’ æ¿€æ´»æ›´å¤šä¸“å®¶

åŠ¨æ€é€‚åº”è¾“å…¥å¤æ‚åº¦!
```

### âŒ æŒ‘æˆ˜

#### 1. è´Ÿè½½ä¸å‡è¡¡

```
é—®é¢˜:
  Expert 1: å¤„ç† 80% tokens  â† è¿‡è½½
  Expert 2: å¤„ç† 15% tokens
  Expert 3: å¤„ç† 5% tokens   â† æµªè´¹

ç»“æœ: å®é™…å¹¶è¡Œåº¦ä½ï¼Œæ•ˆç‡å·®
```

**è§£å†³**: Auxiliary loss, Expert capacity, Expert choice

#### 2. è®­ç»ƒä¸ç¨³å®š

```
é—®é¢˜:
  - Gate å¯èƒ½å´©æºƒ (åªé€‰ä¸€ä¸ªä¸“å®¶)
  - æ¢¯åº¦å¯èƒ½çˆ†ç‚¸
  - ä¸“å®¶å¯èƒ½"æ­»äº¡"(never selected)

è§£å†³:
  - Gradient clipping
  - è¾ƒå°çš„å­¦ä¹ ç‡
  - Warmup with noise
```

#### 3. é€šä¿¡å¼€é”€

```
åˆ†å¸ƒå¼è®­ç»ƒ:
  ä¸“å®¶åˆ†å¸ƒåœ¨ä¸åŒ GPU/æœºå™¨
  Token routing éœ€è¦é€šä¿¡
  é€šä¿¡æˆæœ¬ > è®¡ç®—èŠ‚çœ

All-to-All é€šä¿¡æ˜¯ç“¶é¢ˆ!
```

#### 4. å†…å­˜å ç”¨

```
è™½ç„¶è®¡ç®—å°‘ï¼Œä½†å†…å­˜å¤§:
  8 experts Ã— 512M params/expert = 4GB

éœ€è¦å¤§å†…å­˜ GPU æˆ–æ¨¡å‹å¹¶è¡Œ
```

#### 5. æ¨ç†æ•ˆç‡

```
è®­ç»ƒ: æ‰¹é‡å¤§ï¼Œè´Ÿè½½å‡è¡¡å¥½
æ¨ç†: æ‰¹é‡å° (batch=1)ï¼Œè´Ÿè½½ä¸å‡

å•æ ·æœ¬æ¨ç†å¯èƒ½ä¸é«˜æ•ˆ
```

---

## ğŸŒ å®é™…åº”ç”¨

### 1. GPT-4 (OpenAI)

è™½ç„¶æ¶æ„æœªå…¬å¼€ï¼Œä½†å¹¿æ³›è®¤ä¸ºä½¿ç”¨äº† MoEï¼š

```
æ¨æµ‹æ¶æ„:
  - 8 ä¸ª experts per layer
  - Top-2 routing
  - 1.8T æ€»å‚æ•°
  - ~280B æ¿€æ´»å‚æ•°

æ€§èƒ½:
  - æ¥è¿‘ 1.8T å¯†é›†æ¨¡å‹
  - è®¡ç®—æˆæœ¬æ¥è¿‘ 280B æ¨¡å‹
  - 6Ã— æ•ˆç‡æå‡!
```

### 2. Mixtral 8Ã—7B (Mistral AI)

å¼€æº MoE æ¨¡å‹ï¼š

```
æ¶æ„:
  - 8 ä¸ª experts, æ¯ä¸ª 7B å‚æ•°
  - Top-2 routing
  - æ€»å‚æ•°: 47B
  - æ¿€æ´»å‚æ•°: 13B

æ€§èƒ½:
  - åŒ¹æ•Œ 70B å¯†é›†æ¨¡å‹
  - é€Ÿåº¦æ¥è¿‘ 13B æ¨¡å‹
  - å¼€æºå¯ç”¨!
```

**Mixtral ä»£ç ç‰‡æ®µ**:
```python
class MixtralSparseMoeBlock(nn.Module):
    def __init__(self, config):
        self.hidden_dim = config.hidden_size
        self.ffn_dim = config.intermediate_size
        self.num_experts = config.num_local_experts  # 8
        self.top_k = config.num_experts_per_tok      # 2

        self.gate = nn.Linear(self.hidden_dim, self.num_experts, bias=False)
        self.experts = nn.ModuleList([
            MixtralBLockSparseTop2MLP(config)
            for _ in range(self.num_experts)
        ])
```

### 3. Switch Transformer (Google)

æœ€å¤§è§„æ¨¡çš„ MoEï¼š

```
è§„æ¨¡:
  - 1.6T å‚æ•°
  - 2048 experts!
  - Top-1 routing

è®­ç»ƒ:
  - C4 æ•°æ®é›†
  - æ¯” T5-XXL å¿« 7Ã—

æ€§èƒ½:
  - SOTA on many NLP tasks
```

### 4. GLaM (Google)

ç”¨äºè¯­è¨€å»ºæ¨¡ï¼š

```
æ¶æ„:
  - 1.2T å‚æ•°
  - 64 experts per layer
  - Top-2 routing

æ•ˆç‡:
  - è®­ç»ƒæˆæœ¬: GPT-3 çš„ 1/3
  - æ¨ç†æˆæœ¬: GPT-3 çš„ 1/2
  - æ€§èƒ½: åŒ¹æ•Œ GPT-3
```

### 5. V-MoE (Vision MoE, Google)

å°† MoE åº”ç”¨åˆ°è§†è§‰ï¼š

```
æ¶æ„:
  - Vision Transformer + MoE
  - æ›¿æ¢ ViT çš„ FFN å±‚
  - 32 experts

æ€§èƒ½:
  - ImageNet: 90.35% (SOTA)
  - è®¡ç®—: ViT-Huge çš„ 50%
```

---

## ğŸ”¬ MoE + ViT ç¤ºä¾‹

### Vision MoE Transformer

```python
class VisionMoETransformer(nn.Module):
    def __init__(self, img_size=32, patch_size=8, num_classes=10,
                 embed_dim=128, num_layers=6, num_heads=4,
                 num_experts=8, top_k=2):
        super().__init__()

        # Patch Embedding (æ ‡å‡† ViT)
        self.patch_embed = PatchEmbedding(
            img_size, patch_size, embed_dim
        )

        # Positional Encoding
        num_patches = (img_size // patch_size) ** 2
        self.pos_encoding = PositionalEncoding(embed_dim, max_len=num_patches)

        # MoE Transformer Layers
        self.layers = nn.ModuleList([
            MoETransformerLayer(
                d_model=embed_dim,
                num_heads=num_heads,
                num_experts=num_experts,
                top_k=top_k
            )
            for _ in range(num_layers)
        ])

        # Classification head
        self.norm = nn.LayerNorm(embed_dim)
        self.head = nn.Linear(embed_dim, num_classes)

    def forward(self, x):
        # Patch embedding
        x = self.patch_embed(x)        # (N, num_patches, embed_dim)
        x = self.pos_encoding(x)

        # MoE Transformer layers
        total_aux_loss = 0
        for layer in self.layers:
            x, aux_loss = layer(x)
            total_aux_loss += aux_loss

        # Global average pooling
        x = x.mean(dim=1)              # (N, embed_dim)

        # Classification
        x = self.norm(x)
        logits = self.head(x)          # (N, num_classes)

        return logits, total_aux_loss

# è®­ç»ƒ
model = VisionMoETransformer(num_experts=8, top_k=2)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

for x, y in dataloader:
    logits, aux_loss = model(x)

    # æ€»æŸå¤± = åˆ†ç±»æŸå¤± + è¾…åŠ©æŸå¤±
    task_loss = F.cross_entropy(logits, y)
    total_loss = task_loss + 0.01 * aux_loss

    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()
```

### æ€§èƒ½å¯¹æ¯”

```
é…ç½®: CIFAR-10, img_size=32, patch_size=8

æ ‡å‡† ViT:
  - embed_dim=256, num_layers=6
  - FFN hidden_dim=1024
  - å‚æ•°: ~15M
  - é€Ÿåº¦: 100 img/s
  - å‡†ç¡®ç‡: 88.5%

Vision MoE (8 experts, Top-2):
  - embed_dim=256, num_layers=6
  - 8 experts, hidden_dim=1024 each
  - å‚æ•°: ~60M (4Ã— larger)
  - é€Ÿåº¦: 85 img/s (only 15% slower)
  - å‡†ç¡®ç‡: 91.2% (2.7% better)

æ•ˆç‡:
  - 4Ã— å‚æ•° â†’ 2.7% æ€§èƒ½æå‡
  - åªæ…¢ 15% â†’ å¾ˆå¥½çš„æƒè¡¡!
```

---

## ğŸ“Š æ€»ç»“å¯¹æ¯”è¡¨

### MoE vs æ ‡å‡† Transformer

| ç‰¹æ€§ | æ ‡å‡† Transformer | MoE Transformer |
|------|----------------|----------------|
| **å‚æ•°æ€»é‡** | 1B | 10B |
| **æ¿€æ´»å‚æ•°** | 1B | 1.2B |
| **è®¡ç®—æˆæœ¬** | 1Ã— | 1.2Ã— |
| **æ¨¡å‹å®¹é‡** | æ ‡å‡† | 10Ã— |
| **è®­ç»ƒç¨³å®šæ€§** | é«˜ | ä¸­ç­‰ (éœ€è¦æŠ€å·§) |
| **æ¨ç†æ•ˆç‡** | é«˜ | ä¸­ç­‰ (batch size ä¾èµ–) |
| **å®ç°å¤æ‚åº¦** | ç®€å• | å¤æ‚ |
| **å†…å­˜éœ€æ±‚** | é€‚ä¸­ | é«˜ |
| **ä¸“ä¸šåŒ–** | æ—  | è‡ªåŠ¨å­¦ä¹  |

### ä½•æ—¶ä½¿ç”¨ MoEï¼Ÿ

#### âœ… é€‚åˆä½¿ç”¨ MoE

```
1. å¤§è§„æ¨¡æ¨¡å‹
   - éœ€è¦ >10B å‚æ•°
   - æœ‰è¶³å¤Ÿ GPU å†…å­˜

2. å¤šæ ·åŒ–æ•°æ®
   - æ•°æ®åŒ…å«å¤šä¸ªé¢†åŸŸ
   - ä¸åŒç±»å‹çš„è¾“å…¥

3. æ‰¹é‡è®­ç»ƒ
   - å¤§ batch size (>256)
   - è´Ÿè½½å‡è¡¡å¥½

4. è®¡ç®—å—é™
   - æƒ³è¦å¤§æ¨¡å‹ä½†è®¡ç®—æœ‰é™
   - å‚æ•°å¤šä½† FLOPs å°‘
```

#### âŒ ä¸é€‚åˆä½¿ç”¨ MoE

```
1. å°æ¨¡å‹
   - <1B å‚æ•°
   - MoE å¼€é”€ä¸å€¼å¾—

2. å•ä¸€ä»»åŠ¡
   - æ•°æ®å•ä¸€
   - ä¸“å®¶åˆ†å·¥æ— æ„ä¹‰

3. å° batch æ¨ç†
   - batch size = 1
   - è´Ÿè½½ä¸å‡ï¼Œæ•ˆç‡ä½

4. å†…å­˜å—é™
   - GPU å†…å­˜å°
   - è£…ä¸ä¸‹å¤šä¸ªä¸“å®¶
```

---

## ğŸ”® æœªæ¥æ–¹å‘

### 1. æ›´é«˜æ•ˆçš„è·¯ç”±

```
å½“å‰: Softmax + Top-K
  - ç®€å•ä½†å¯èƒ½æ¬¡ä¼˜

æœªæ¥: å­¦ä¹ è·¯ç”±ç­–ç•¥
  - å¼ºåŒ–å­¦ä¹ è·¯ç”±
  - å±‚æ¬¡åŒ–è·¯ç”±
  - åŠ¨æ€è·¯ç”±
```

### 2. è‡ªé€‚åº”ä¸“å®¶æ•°é‡

```
å½“å‰: å›ºå®šæ•°é‡ä¸“å®¶
  - æ‰€æœ‰å±‚ç›¸åŒæ•°é‡

æœªæ¥: åŠ¨æ€ä¸“å®¶
  - æµ…å±‚å°‘ä¸“å®¶
  - æ·±å±‚å¤šä¸“å®¶
  - æ ¹æ®éœ€è¦è°ƒæ•´
```

### 3. ç»†ç²’åº¦ MoE

```
å½“å‰: Layer-level MoE
  - æ•´ä¸ª FFN æ›¿æ¢

æœªæ¥: Neuron-level MoE
  - ç¥ç»å…ƒçº§åˆ«ç¨€ç–
  - æ›´ç»†ç²’åº¦æ§åˆ¶
```

### 4. MoE + å…¶ä»–æŠ€æœ¯

```
MoE + LoRA:
  - ä¸“å®¶ä½¿ç”¨ low-rank adapters
  - æ›´å°‘å‚æ•°

MoE + Quantization:
  - é‡åŒ–ä¸“å®¶æƒé‡
  - æ›´å°å†…å­˜

MoE + Distillation:
  - è’¸é¦åˆ°å°æ¨¡å‹
  - ä¿ç•™ä¸“ä¸šåŒ–
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Shazeer et al.** "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer" (2017)
   - åŸå§‹ MoE for NLP è®ºæ–‡

2. **Fedus et al.** "Switch Transformers: Scaling to Trillion Parameter Models" (2021)
   - Google Switch Transformer

3. **Riquelme et al.** "Scaling Vision with Sparse Mixture of Experts" (2021)
   - Vision MoE (V-MoE)

4. **Zhou et al.** "Mixture-of-Experts with Expert Choice Routing" (2022)
   - Expert Choice è·¯ç”±

5. **Jiang et al.** "Mixtral of Experts" (2024)
   - Mistral AI å¼€æº MoE

---

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

1. **æ ¸å¿ƒæ€æƒ³**:
   - ç”¨å¤šä¸ªå°ä¸“å®¶æ›¿ä»£ä¸€ä¸ªå¤§ FFN
   - ç¨€ç–æ¿€æ´» â†’ å¤§å®¹é‡ + ä½è®¡ç®—

2. **å…³é”®ç»„ä»¶**:
   - Gating Network: è·¯ç”±å†³ç­–
   - Expert Networks: ä¸“ä¸šå¤„ç†
   - Top-K Selection: ç¨€ç–æ¿€æ´»

3. **ä¸»è¦ä¼˜åŠ¿**:
   - å‚æ•°æ•ˆç‡: 10Ã— å‚æ•°, 1.2Ã— è®¡ç®—
   - ä¸“ä¸šåŒ–: è‡ªåŠ¨å­¦ä¹ é¢†åŸŸä¸“å®¶
   - å¯æ‰©å±•: çº¿æ€§æ‰©å±•åˆ°æ•°åƒä¸“å®¶

4. **ä¸»è¦æŒ‘æˆ˜**:
   - è´Ÿè½½å‡è¡¡: éœ€è¦è¾…åŠ©æŸå¤±
   - è®­ç»ƒç¨³å®šæ€§: éœ€è¦ç‰¹æ®ŠæŠ€å·§
   - é€šä¿¡å¼€é”€: åˆ†å¸ƒå¼è®­ç»ƒç“¶é¢ˆ

5. **å®é™…åº”ç”¨**:
   - GPT-4 (æ¨æµ‹)
   - Mixtral 8Ã—7B
   - Switch Transformer
   - V-MoE

**MoE æ˜¯æ‰©å±•å¤§æ¨¡å‹çš„å…³é”®æŠ€æœ¯ä¹‹ä¸€ï¼** ğŸš€
